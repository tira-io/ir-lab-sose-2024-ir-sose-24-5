{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tira.third_party_integrations import ensure_pyterrier_is_loaded, persist_and_normalize_run\n",
    "from tira.rest_api_client import Client\n",
    "import pyterrier as pt\n",
    "\n",
    "# Create a REST client to the TIRA platform for retrieving the pre-indexed data.\n",
    "ensure_pyterrier_is_loaded()\n",
    "tira = Client()\n",
    "\n",
    "# The dataset: the union of the IR Anthology and the ACL Anthology\n",
    "# This line creates an IRDSDataset object and registers it under the name provided as an argument.\n",
    "dataset = 'ir-acl-anthology-20240504-training'\n",
    "pt_dataset = pt.get_dataset('irds:ir-lab-sose-2024/ir-acl-anthology-20240504-training')\n",
    "\n",
    "\n",
    "# A (pre-built) PyTerrier index loaded from TIRA\n",
    "index = tira.pt.index('ir-lab-sose-2024/tira-ir-starter/Index (tira-ir-starter-pyterrier)', pt_dataset)\n",
    "\n",
    "bm25 = pt.BatchRetrieve(index, wmodel=\"BM25\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "qe = pt.rewrite.Bo1QueryExpansion(index)\n",
    "qe_2 = pt.rewrite.KLQueryExpansion(index)\n",
    "qe_3 = pt.rewrite.RM3(index)\n",
    "qe_4 = pt.rewrite.Bo1QueryExpansion(index, fb_terms=20)\n",
    "gpt_cot = tira.pt.transform_queries('workshop-on-open-web-search/tu-dresden-03/qe-gpt3.5-cot', dataset, prefix='llm_expansion_')\n",
    "gpt_sq_fs = tira.pt.transform_queries('workshop-on-open-web-search/tu-dresden-03/qe-gpt3.5-sq-fs', dataset, prefix='llm_expansion_')\n",
    "gpt_sq_zs = tira.pt.transform_queries('ir-benchmarks/tu-dresden-03/qe-gpt3.5-sq-zs', dataset, prefix='llm_expansion_')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokeniser = pt.autoclass(\"org.terrier.indexing.tokenisation.Tokeniser\").getTokeniser()\n",
    "\n",
    "def pt_tokenize(text):\n",
    "    return ' '.join(tokeniser.getTokens(text))\n",
    "\n",
    "def expand_query(topic):\n",
    "  ret = ' '.join([topic['query'], topic['query'], topic['query'],  topic['query'],  topic['query'], topic['llm_expansion_query']])\n",
    "\n",
    "  # apply the tokenization\n",
    "  return pt_tokenize(ret)\n",
    "\n",
    "pt_expand_query = pt.apply.query(expand_query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "qe_pipeline = bm25 >> qe >> bm25\n",
    "qe_pipeline_2 = bm25 >> qe_2 >> bm25\n",
    "qe_pipeline_3 = bm25 >> qe_3 >> bm25\n",
    "qe_pipeline_4 = bm25 >> qe_4 >> bm25\n",
    "pipeline_gpt_cot = (gpt_cot >> pt_expand_query) >> bm25\n",
    "pipeline_gpt_sq_fs = (gpt_sq_fs >> pt_expand_query) >> bm25\n",
    "pipeline_gpt_sq_zs = (gpt_sq_zs >> pt_expand_query) >> bm25"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "01:13:36.255 [main] WARN org.terrier.querying.RM1 - Did not identify any usable candidate expansion terms from docid 125137 among 5 possibilities\n",
      "01:13:36.533 [main] WARN org.terrier.querying.RM1 - Did not identify any usable candidate expansion terms from docid 116910 among 4 possibilities\n"
     ]
    }
   ],
   "source": [
    "run_base = bm25(pt_dataset.get_topics('text'))\n",
    "run_qe = qe_pipeline(pt_dataset.get_topics('text')) #Bo1QueryExpansion\n",
    "run_qe_2 = qe_pipeline_2(pt_dataset.get_topics('text')) #KLQueryExpansion\n",
    "run_qe_3 = qe_pipeline_3(pt_dataset.get_topics('text')) #RM3\n",
    "run_qe_4 = qe_pipeline_4(pt_dataset.get_topics('text')) #Bo1QueryExpansion 2x more terms\n",
    "run_pipeline_gpt_cot = pipeline_gpt_cot(pt_dataset.get_topics('text'))\n",
    "run_pipeline_gpt_sq_fs = pipeline_gpt_sq_fs(pt_dataset.get_topics('text'))\n",
    "run_pipeline_gpt_sq_zs = pipeline_gpt_sq_zs(pt_dataset.get_topics('text'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The run file is normalized outside the TIRA sandbox, I will store it at \"../runs/base\".\n",
      "Done. run file is stored under \"../runs/base/run.txt\".\n",
      "The run file is normalized outside the TIRA sandbox, I will store it at \"../runs/qe\".\n",
      "Done. run file is stored under \"../runs/qe/run.txt\".\n",
      "The run file is normalized outside the TIRA sandbox, I will store it at \"../runs/qe_2\".\n",
      "Done. run file is stored under \"../runs/qe_2/run.txt\".\n",
      "The run file is normalized outside the TIRA sandbox, I will store it at \"../runs/qe_3\".\n",
      "Done. run file is stored under \"../runs/qe_3/run.txt\".\n",
      "The run file is normalized outside the TIRA sandbox, I will store it at \"../runs/qe_4\".\n",
      "Done. run file is stored under \"../runs/qe_4/run.txt\".\n",
      "The run file is normalized outside the TIRA sandbox, I will store it at \"../runs/qe_gpt_cot\".\n",
      "Done. run file is stored under \"../runs/qe_gpt_cot/run.txt\".\n",
      "The run file is normalized outside the TIRA sandbox, I will store it at \"../runs/qe_gpt_sq_fs\".\n",
      "Done. run file is stored under \"../runs/qe_gpt_sq_fs/run.txt\".\n",
      "The run file is normalized outside the TIRA sandbox, I will store it at \"../runs/qe_gpt_sq_fz\".\n",
      "Done. run file is stored under \"../runs/qe_gpt_sq_fz/run.txt\".\n"
     ]
    }
   ],
   "source": [
    "persist_and_normalize_run(run_base, system_name='bm25-baseline', default_output='../runs/base')\n",
    "persist_and_normalize_run(run_qe, system_name='query-expansion_Bo1QE', default_output='../runs/qe')\n",
    "persist_and_normalize_run(run_qe_2, system_name='query-expansion_KLQE', default_output='../runs/qe_2')\n",
    "persist_and_normalize_run(run_qe_3, system_name='query-expansion_RM3', default_output='../runs/qe_3')\n",
    "persist_and_normalize_run(run_qe_4, system_name='query-expansion_Bo1QEx2', default_output='../runs/qe_4')\n",
    "persist_and_normalize_run(run_pipeline_gpt_cot, system_name='llm-query-expansion-gpt-cot', default_output='../runs/qe_gpt_cot')\n",
    "persist_and_normalize_run(run_pipeline_gpt_sq_fs, system_name='llm-query-expansion-gpt-sq-fs', default_output='../runs/qe_gpt_sq_fs')\n",
    "persist_and_normalize_run(run_pipeline_gpt_sq_zs, system_name='llm-query-expansion-gpt-sq-fz', default_output='../runs/qe_gpt_sq_fz')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
